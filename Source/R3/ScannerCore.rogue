module RogueC

# Generated by Froley. WARNING: WILL BE OVERWRITTEN.

$include "CompileError.rogue"
$include "ScanTable.rogue"
$include "Token.rogue"
$include "TokenType.rogue"

class ScannerCore [abstract]
  DEFINITIONS
    ip_tokenize_another = 0
    ip_scan_comment = 1
    ip_scan_id_or_keyword = 2
    ip_scan_number = 3
    ip_scan_integer = 4
    ip_scan_binary_integer = 5
    ip_scan_octal_integer = 6
    ip_scan_hex_integer = 7
    ip_tokenize_string = 8
    ip_scan_string = 9
    ip_tokenize_character_or_string = 10
    ip_scan_single_quote_string = 11
    ip_tokenize_two_quote_string = 12
    ip_scan_two_quote_string = 13
    ip_scan_character = 14
    ip_read_hex4 = 15
    ip_read_hex2 = 16
    ip_read_hex_digit = 17
    ip_tokenize_verbatim_string = 18
    ip_scan_verbatim_string = 19

  PROPERTIES
    _filepath     : String
    _scanner      : Rogue::Scanner
    line          = 1
    column        = 1

    tokens        = Token[]
    buffer        = String()
    output        = String()

    start_ip      = 0
    halt          = false

    _position_stack  = Int32[]
    _line_stack      = Int32[]
    _column_stack    = Int32[]
    _token_pos_stack = Int32[]

    # GENERATED PROPERTIES
    ch           : Character
    count        : Int32
    saved_buffer : String
    base         : Int32
    hex2         : Int32
    hex4         : Int32
    hex_digit    : Int32
    value        : Int32
    digits       : Int32
    _scan_pattern_0 = ScanPattern( "[ \r\t]*" )
    _scan_pattern_1 = ScanPattern( "{[_a-zA-Z][_a-zA-Z0-9]*}" )
    _scan_pattern_2 = ScanPattern( "[0-9]*" )
    _scan_pattern_3 = ScanPattern( "[^\n]*" )
    _scan_pattern_4 = ScanPattern( "{----[-]*}" )
    _scan_pattern_5 = ScanPattern( "{====[=]*}" )
    _scan_pattern_6 = ScanPattern( "[ ]+" )
    _scan_pattern_7 = ScanPattern( "[0-9]" )
    _scan_pattern_8 = ScanPattern( "{[.][0-9]}" )
    _scan_pattern_9 = ScanPattern( "[eE]" )
    _scan_pattern_10 = ScanPattern( "[+-]" )
    _scan_pattern_11 = ScanPattern( "[0-9]+" )
    _scan_pattern_12 = ScanPattern( "[_]+" )
    _scan_pattern_13 = ScanPattern( "[01]+" )
    _scan_pattern_14 = ScanPattern( "[0-7]+" )
    _scan_pattern_15 = ScanPattern( "[0-9A-Fa-f]+" )
    _scan_pattern_16 = ScanPattern( "[0-9a-fA-F]" )
    _scan_pattern_17 = ScanPattern( "[ ]*" )
    _scan_table_0 = ScanTable("iFr/Hgo+IkAnQkBIJGomhnwthwIqhxBchxYhhxhehx59hyRdhyYphyg6hyosh1w8h14/h2wuh3Z8iAxbiBY9iCA+iCp7iDQoiDYliDgriD47iEgviEp+iFQAAAEAAgEnRgMAJAR8UltUe1Z0WAQANgA3AP8Bclz/AWFg/wFjZP8BZWhXAP8KZIEAZYE6ZoIwaYJqc4QkbIR+bYVYcoVqdIZEdYZa/wFlgQT/AWaBCP8CYYEOaYEw/wF1gRL/AWyBFv8BdIEa/wFWgR7/AWGBIv8BbIEm/wF1gSr/AWWBLgUA/wFugTT/AWWBOAYA/wNsgUJugVR4gh7/AXOBRv8BZYFK/wFJgU7/AWaBUgcA/wFkgVj/A0mBYEyBZk2CDP8BZoFkCAD/AW+Bav8BY4Fu/wFhgXL/AWyBdv8BTYF6/wFhgX7/AWOCAv8BcoIG/wFvggoJAP8BYYIQ/wFjghT/AXKCGP8Bb4IcCgD/AWmCIv8Bc4Im/wF0gir/AXOCLgsA/wFpgjT/AWyCOP8BZYI8/wJCgkJTglT/AXmCRv8BdIJK/wFlgk7/AXOCUgwA/wF0glj/AXKCXP8BaYJg/wFugmT/AWeCaA0A/wRmgnRugnZzgwxkhCIOAP8BY4J6/wFsgn7/AXWDAv8BZIMG/wFlgwoPAP8FQ4MYRIM2RYNQUINeUoQA/wFvgxz/AW2DIP8BcIMk/wFvgyj/AXWDLP8BboMw/wFkgzQQAP8BZYM6/wFmgz7/AWmDQv8BboNG/wFlg0r/AWSDThEA/wFug1T/AXWDWP8BbYNcEgD/AXKDYv8BaYNm/wFtg2r/AWmDbv8BdINy/wFpg3b/AXaDev8BZYN+EwD/AWWEBP8BZoQI/wFlhAz/AXKEEP8BZYQU/wFuhBj/AWOEHP8BZYQgFAAVAP8CdIQqb4Q8/wFyhC7/AWmEMv8BboQ2/wFnhDoWAP8BdYRA/wFyhET/AWOESP8BZYRM/wJGhFJMhHD/AWmEVv8BbIRa/wFlhF7/AXCEYv8BYYRm/wF0hGr/AWiEbh0A/wFphHT/AW6EeP8BZYR8HgD/AW+FAv8CY4UId4U+/wFhhQz/AWyFEP8CRIUWTYUs/wFlhRr/AWaFHv8BaYUi/wFuhSb/AWWFKhcA/wFhhTD/AWOFNP8BcoU4/wFvhTwYAP8BZYVC/wFyhUb/AWOFSv8BYYVO/wFzhVL/AWWFVhkA/wFhhVz/AWOFYP8BcoVk/wFvhWgaAP8CZYVwb4Ya/wFxhXT/AXWFeP8BaYV8/wFyhgD/AWWGBP8BUoYI/wFvhgz/AWeGEP8BdYYU/wFlhhgbAP8BZ4Ye/wF1hiL/AWWGJv8BVoYq/wFlhi7/AXKGMv8Bc4Y2/wFphjr/AW+GPv8BboZCHAD/AWGGSP8BcoZM/wFnhlD/AWWGVP8BdIZYHwD/AXCGXv8BcIZi/wFlhmb/AXKGav8BY4Zu/wFhhnL/AXOGdv8BZYZ6IAAhAT2HAGAAQwM+hwothww9hw4iAEQAWwAjAT2HFFwAJQAmAT2HHEUAJwE9hyJfACgAKQAqACsDOocyPIc0PodCLAD/ATyHOP8BOoc8PwE9h0BjAP8BPodG/wI6h0w+h1JQAT2HUGQA/wE6h1ZSAT2HWmUALQBBAz6HZj2HaDyHai4APgBCAE4CLodyOod0LwBPAEsDLod+W4gIPYgKMAI8iAQ+iAYxADIAMwBmAFkCfIgSPYgUNABhAEcCXYgcPogeNQBIADkCPYgmPogoOAA6ADwCPYgwPogyOwA9AEYASQBKAT2IPF4ATAIriEQ9iEZNAFoAVABVAi+IUD2IUlYAXQBYAT2IWGIA")
    _scan_table_1 = ScanTable("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")
    _scan_table_2 = ScanTable("YgABRwT/AUwI/wFPDP8BQhD/AUEU/wFMGP8BIBz/AlAiTUj/AVIm/wFPKv8BUC7/AUUy/wFSNv8BVDr/AUk+/wFFQv8BU0YBAP8BRUz/AVRQ/wFIVP8BT1j/AURc/wFTYAIA")
    _scan_table_3 = ScanTable("EgABMAT/A2IMYw54EAEAAgADAA==")

  METHODS
    method init( file:File )
      init( file.filepath, Rogue::Scanner(file) )
      line   = 1
      column = 1

    method init( filepath:String, content:String, line=1, column=1 )
      init( filepath, Rogue::Scanner(content).[line=line, column=column] )

    method init( _filepath, _scanner )
      noAction

    method mark_beginning_of_line [abstract]

    method process_comment [abstract]

    method use_DateTime [abstract]

    method use_File [abstract]

    method use_Value [abstract]

    method use_Process [abstract]

    method use_Scanner [abstract]

    method use_Set [abstract]

    method execute( ip:Int32 )
      _clear_state
      _execute( ip )

    method tokenize( ip=null:Int32? )->Token[]
      if (ip) start_ip = ip.value
      _clear_state
      while (_execute(start_ip) or not halt)
        buffer.clear
      endWhile
      _on_output_line # flush any buffered output
      return tokens

    method _add( type:TokenType )
      if (type.attributes & TokenType.ATTRIBUTE_CONTENT)
        tokens.add( _t(type,buffer.cloned) )
      else
        tokens.add( _t(type) )
      endIf
      buffer.clear

    method _clear_state
      tokens = Token[]
      buffer.clear
      output.clear
      halt = false

    method _describe_character( c:Character )->String
      if (c == 10 or c == 13)       return "end of line";
      elseIf (c >= 32 and c != 127) return "'$'" (c)
      else                          return "'$'" (c.to_escaped_ascii)

    method _discard_position
      if (_position_stack.is_empty)
        _throw_syntax_error( "discardPosition without prior savePosition." )
      endIf
      _position_stack.remove_last
      _line_stack.remove_last
      _column_stack.remove_last
      _token_pos_stack.remove_last

    method _is_next( text:String )->Logical
      local location = _scanner.location
      local result = _scanner.consume( text )
      _scanner.location = location
      return result

    method _must_consume( ch:Character )
      if (_scanner.consume(ch)) return
      local message = "Syntax error - expected $, found " (_describe_character(ch))
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _must_consume( st:String )
      if (_scanner.consume(st)) return
      _throw_expected_string_error( "'$'" (st.to_escaped_ascii("'")) )

    method _must_consume( pattern:ScanPattern )
      if (pattern.scan(_scanner)) return
      _throw_expected_string_error( pattern->String )

    method _next_is( text:String )->Logical
      if (not _scanner.has_another(text.count)) return false
      local pos = _scanner.position
      forEach (ch at index in text)
        if (ch != _scanner.data[pos+index]) return false
      endForEach
      return true

    method _on_output_line
      # Default behavior: print out 'output' and clear it. Can override this method.
      print( output )
      flush
      output.clear

    method _restore_position
      if (_position_stack.is_empty)
        _throw_syntax_error( "restorePosition without prior savePosition." )
      endIf
      _scanner.position = _position_stack.remove_last
      _scanner.line     = _line_stack.remove_last
      _scanner.column   = _column_stack.remove_last
      tokens.discard_from( _token_pos_stack.remove_last )

    method _save_position
      _position_stack.add( _scanner.position )
      _line_stack.add( _scanner.line )
      _column_stack.add( _scanner.column )
      _token_pos_stack.add( tokens.count )

    method _scan( ch:Character )->Logical
      if (not _scanner.consume(ch)) return false
      buffer.print ch
      return true

    method _scan( text:String )->Logical
      if (not _scanner.consume(text)) return false
      buffer.print text
      return true

    method _t( type:TokenType, content=null:String )->Token
      return Token( type, _filepath, _scanner.source, line, column, content )

    method _throw_expected_string_error( st:String )
      local message = "Syntax error - expected $, found " (st)
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _throw_syntax_error( message=null:String )
      if (not message)
        local builder = String()
        builder.print "Syntax error - unexpected "
        if (not _scanner.has_another)
          builder.println "end of input."
        else
          builder.[ print(_describe_character(_scanner.peek)), print('.') ]
        endIf
        message = builder
      endIf
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _execute( ip:Int32 )->Logical
      which (ip)
        case ip_tokenize_another: return r_tokenize_another
        case ip_scan_comment: return r_scan_comment
        case ip_scan_id_or_keyword: return r_scan_id_or_keyword
        case ip_scan_number: return r_scan_number
        case ip_scan_integer: return r_scan_integer
        case ip_scan_binary_integer: return r_scan_binary_integer
        case ip_scan_octal_integer: return r_scan_octal_integer
        case ip_scan_hex_integer: return r_scan_hex_integer
        case ip_tokenize_string: return r_tokenize_string
        case ip_scan_string: return r_scan_string
        case ip_tokenize_character_or_string: return r_tokenize_character_or_string
        case ip_scan_single_quote_string: return r_scan_single_quote_string
        case ip_tokenize_two_quote_string: return r_tokenize_two_quote_string
        case ip_scan_two_quote_string: return r_scan_two_quote_string
        case ip_scan_character: return r_scan_character
        case ip_read_hex4: return r_read_hex4
        case ip_read_hex2: return r_read_hex2
        case ip_read_hex_digit: return r_read_hex_digit
        case ip_tokenize_verbatim_string: return r_tokenize_verbatim_string
        case ip_scan_verbatim_string: return r_scan_verbatim_string
        others
          halt = true
          return false
      endWhich

    method r_tokenize_another->Logical
      ch = _scanner.peek
      if ((((ch==' ') or (ch=='\r')) or (ch=='\t')))
        _scan_pattern_0.scan(_scanner)
      endIf
      line   = _scanner.line
      column = _scanner.column
      ch = _scanner.peek
      if ((((ch=='#') or ((ch=='-') and _next_is("----"))) or ((ch=='=') and _next_is("===="))))
        if (not r_scan_comment) return false
      endIf
      if ((not _scanner.has_another))
        _add( TokenType.EOL )
        halt = true
        return false
      endIf
      if (((ch=='.') and _scanner.consume("...")))
        while ((_scanner.has_another and (not _scanner.consume('\n'))))
          if ((not (_scanner.consume(' ') or _scanner.consume('\t'))))
            if (_scanner.next_is('#'))
              if (not r_scan_comment) return false
              return false
            endIf
            _throw_syntax_error("End of line expected.")
            return false
          endIf
        endWhile
        return false
      endIf
      if (((((ch>='a') and (ch<='z')) or ((ch>='A') and (ch<='Z'))) or (ch=='_')))
        if (not r_scan_id_or_keyword) return false
      endIf
      _scan_table_0.reset
      contingent
        block n=1
          while (_scanner.has_another(n))
            if (not _scan_table_0.accept(_scanner.peek(n-1)))
              escapeWhile
            endIf
            ++n
          endWhile
          necessary (_scan_table_0.has_product)
          loop (_scan_table_0.match_count) _scanner.read
        endBlock
        which (_scan_table_0.product)
          case 0
            mark_beginning_of_line

            _add( TokenType.EOL )
            return false
          case 1
            if (not r_tokenize_string) return false
          case 2
            if (not r_tokenize_character_or_string) return false
          case 3
            if (not r_tokenize_two_quote_string) return false
          case 4
            if (not r_tokenize_verbatim_string) return false
          case 5
            _add( TokenType.META_DEFAULT_VALUE )
            return false
          case 6
            _add( TokenType.META_DEFINE )
            return false
          case 7
            _add( TokenType.META_ELSE_IF )
            return false
          case 8
            _add( TokenType.META_END_IF )
            return false
          case 9
            _add( TokenType.META_END_LOCAL_MACRO )
            return false
          case 10
            _add( TokenType.META_END_MACRO )
            return false
          case 11
            _add( TokenType.META_EXISTS )
            return false
          case 12
            _add( TokenType.META_FILE_BYTES )
            return false
          case 13
            _add( TokenType.META_FILE_STRING )
            return false
          case 14
            _add( TokenType.META_IF )
            return false
          case 15
            _add( TokenType.META_INCLUDE )
            return false
          case 16
            _add( TokenType.META_IS_COMPOUND )
            return false
          case 17
            _add( TokenType.META_IS_DEFINED )
            return false
          case 18
            _add( TokenType.META_IS_ENUM )
            return false
          case 19
            _add( TokenType.META_IS_PRIMITIVE )
            return false
          case 20
            _add( TokenType.META_IS_REFERENCE )
            return false
          case 21
            _add( TokenType.META_JOIN_IDS )
            return false
          case 22
            _add( TokenType.META_JOIN_STRINGS )
            return false
          case 23
            _add( TokenType.META_LOCAL_DEFINE )
            return false
          case 24
            _add( TokenType.META_LOCAL_MACRO )
            return false
          case 25
            _add( TokenType.META_LOWERCASE )
            return false
          case 26
            _add( TokenType.META_MACRO )
            return false
          case 27
            _add( TokenType.META_REQUIRE_ROGUE )
            return false
          case 28
            _add( TokenType.META_ROGUE_VERSION )
            return false
          case 29
            _add( TokenType.META_SOURCE_FILEPATH )
            return false
          case 30
            _add( TokenType.META_SOURCE_LINE )
            return false
          case 31
            _add( TokenType.META_TARGET )
            return false
          case 32
            _add( TokenType.META_UPPERCASE )
            return false
          case 33
            _add( TokenType.SYMBOL_AMPERSAND )
            return false
          case 34
            _add( TokenType.SYMBOL_ARROW )
            return false
          case 35
            _add( TokenType.SYMBOL_ASTERISK )
            return false
          case 36
            _add( TokenType.SYMBOL_AT )
            return false
          case 37
            _add( TokenType.SYMBOL_BACKSLASH )
            return false
          case 38
            _add( TokenType.SYMBOL_BANG )
            return false
          case 39
            _add( TokenType.SYMBOL_CARET )
            return false
          case 40
            _add( TokenType.SYMBOL_CLOSE_CURLY )
            return false
          case 41
            _add( TokenType.SYMBOL_CLOSE_SQUARE )
            return false
          case 42
            _add( TokenType.SYMBOL_CLOSE_PAREN )
            return false
          case 43
            _add( TokenType.SYMBOL_COLON )
            return false
          case 44
            _add( TokenType.SYMBOL_COLON_COLON )
            return false
          case 45
            _add( TokenType.SYMBOL_COMMA )
            return false
          case 46
            _add( TokenType.SYMBOL_COMPARE )
            return false
          case 47
            _add( TokenType.SYMBOL_QUESTION_DOT )
            return false
          case 48
            _add( TokenType.SYMBOL_DOTDOT )
            return false
          case 49
            _add( TokenType.SYMBOL_DOTDOTLT )
            return false
          case 50
            _add( TokenType.SYMBOL_DOTDOTGT )
            return false
          case 51
            _add( TokenType.SYMBOL_DOT_OPEN_SQUARE )
            return false
          case 52
            _add( TokenType.SYMBOL_DOUBLE_VERTICAL_BAR )
            return false
          case 53
            _add( TokenType.SYMBOL_EMPTY_SQUARE_BRACKETS )
            return false
          case 54
            _add( TokenType.SYMBOL_VALUE_LIST )
            return false
          case 55
            _add( TokenType.SYMBOL_VALUE_TABLE )
            return false
          case 56
            _add( TokenType.SYMBOL_EQ )
            return false
          case 57
            _add( TokenType.SYMBOL_EQUALS )
            return false
          case 58
            _add( TokenType.SYMBOL_FAT_ARROW )
            return false
          case 59
            _add( TokenType.SYMBOL_GE )
            return false
          case 60
            _add( TokenType.SYMBOL_GT )
            return false
          case 61
            _add( TokenType.SYMBOL_GTGT )
            return false
          case 62
            _add( TokenType.SYMBOL_LE )
            return false
          case 63
            _add( TokenType.SYMBOL_LEFT_SHIFT )
            return false
          case 64
            _add( TokenType.SYMBOL_LEFT_SHIFT_EQUALS )
            return false
          case 65
            _add( TokenType.SYMBOL_LT )
            return false
          case 66
            _add( TokenType.SYMBOL_LTLT )
            return false
          case 67
            _add( TokenType.SYMBOL_MINUS )
            return false
          case 68
            _add( TokenType.SYMBOL_MINUS_MINUS )
            return false
          case 69
            _add( TokenType.SYMBOL_NE )
            return false
          case 70
            _add( TokenType.SYMBOL_OPEN_CURLY )
            return false
          case 71
            _add( TokenType.SYMBOL_OPEN_SQUARE )
            return false
          case 72
            _add( TokenType.SYMBOL_OPEN_SQUARE_GT )
            return false
          case 73
            _add( TokenType.SYMBOL_OPEN_PAREN )
            return false
          case 74
            _add( TokenType.SYMBOL_PERCENT )
            return false
          case 75
            _add( TokenType.SYMBOL_PERIOD )
            return false
          case 76
            _add( TokenType.SYMBOL_PLUS )
            return false
          case 77
            _add( TokenType.SYMBOL_PLUS_PLUS )
            return false
          case 78
            _add( TokenType.SYMBOL_QUESTION )
            return false
          case 79
            _add( TokenType.SYMBOL_QUESTION_COLON )
            return false
          case 80
            _add( TokenType.SYMBOL_RIGHT_SHIFT )
            return false
          case 81
            _add( TokenType.SYMBOL_RIGHT_SHIFT_EQUALS )
            return false
          case 82
            _add( TokenType.SYMBOL_RIGHT_SHIFT_X )
            return false
          case 83
            _add( TokenType.SYMBOL_RIGHT_SHIFT_X_EQUALS )
            return false
          case 84
            _add( TokenType.SYMBOL_SEMICOLON )
            return false
          case 85
            _add( TokenType.SYMBOL_SLASH )
            return false
          case 86
            _add( TokenType.SYMBOL_SLASH_SLASH )
            return false
          case 87
            _add( TokenType.SYMBOL_BRIEF_TRACE )
            return false
          case 88
            _add( TokenType.SYMBOL_TILDE )
            return false
          case 89
            _add( TokenType.SYMBOL_VERTICAL_BAR )
            return false
          case 90
            _add( TokenType.SYMBOL_PLUS_EQUALS )
            return false
          case 91
            _add( TokenType.SYMBOL_MINUS_EQUALS )
            return false
          case 92
            _add( TokenType.SYMBOL_TIMES_EQUALS )
            return false
          case 93
            _add( TokenType.SYMBOL_DIVIDE_EQUALS )
            return false
          case 94
            _add( TokenType.SYMBOL_MOD_EQUALS )
            return false
          case 95
            _add( TokenType.SYMBOL_POWER_EQUALS )
            return false
          case 96
            _add( TokenType.SYMBOL_BITWISE_AND_EQUALS )
            return false
          case 97
            _add( TokenType.SYMBOL_BITWISE_OR_EQUALS )
            return false
          case 98
            _add( TokenType.SYMBOL_BITWISE_XOR_EQUALS )
            return false
          case 99
            _add( TokenType.SYMBOL_SHIFT_LEFT_EQUALS )
            return false
          case 100
            _add( TokenType.SYMBOL_SHIFT_RIGHT_EQUALS )
            return false
          case 101
            _add( TokenType.SYMBOL_SHIFT_RIGHT_X_EQUALS )
            return false
          case 102
            _add( TokenType.SYMBOL_ACCESS_EQUALS )
            return false
          others
            necessary (false)
        endWhich
      endContingent
      if ((ch=='$'))
        _scan('$')
        if (_scan_pattern_1.scan(_scanner,buffer))
          _add( TokenType.PLACEHOLDER )
          return false
        endIf
        if (_scan_pattern_2.scan(_scanner,buffer))
          _add( TokenType.GENERIC_FN_ARG )
          return false
        endIf
        _add( TokenType.SYMBOL_DOLLAR )
        return false
      endIf
      if (not r_scan_number) return false
      _throw_syntax_error
      return false
      return true

    method r_scan_comment->Logical
      if (_scan('#'))
        if (_scan('{'))
          count = 1
          while (_scanner.has_another)
            ch = _scanner.read
            buffer.print(ch)
            if ((ch=='\n'))
              saved_buffer = buffer
              _add( TokenType.EOL )
              buffer.clear.print saved_buffer
            elseIf ((ch=='#'))
              if (_scan('{'))
                ++count
              endIf
            elseIf ((ch=='}'))
              if (_scan('#'))
                --count
                if ((count==0))
                  process_comment

                  return false
                endIf
              endIf
            endIf
          endWhile
          _throw_syntax_error("Unterminated multi-line comment.")
          return false
        else
          if (_scan_pattern_3.scan(_scanner,buffer))
            process_comment

            _scanner.consume('\n')
            mark_beginning_of_line

            _add( TokenType.EOL )
            return false
          endIf
        endIf
      elseIf ((_scan_pattern_4.scan(_scanner) or _scan_pattern_5.scan(_scanner)))
        _scan_pattern_3.scan(_scanner,buffer)
        process_comment

        _scanner.consume('\n')
        mark_beginning_of_line

        _add( TokenType.EOL )
        return false
      else
        return true
      endIf
      return true

    method r_scan_id_or_keyword->Logical
      if ((not _scan_pattern_1.scan(_scanner,buffer)))
        return true
      endIf
      _scan_table_1.reset
      contingent
        necessary (_scan_table_1.accept(forEach in buffer))
        which (_scan_table_1.product)
          case 1
            use_DateTime

            _add( TokenType.IDENTIFIER )
            return false
          case 2
            use_File

            _add( TokenType.IDENTIFIER )
            return false
          case 3
            use_Value

            _add( TokenType.IDENTIFIER )
            return false
          case 4
            use_Process

            _add( TokenType.IDENTIFIER )
            return false
          case 5
            use_Scanner

            _add( TokenType.IDENTIFIER )
            return false
          case 6
            use_Set

            _add( TokenType.IDENTIFIER )
            return false
          case 7
            use_DateTime

            _add( TokenType.IDENTIFIER )
            return false
          case 8
            use_DateTime

            _add( TokenType.IDENTIFIER )
            return false
          case 9
            use_DateTime

            _add( TokenType.IDENTIFIER )
            return false
          case 10
            use_Value

            _add( TokenType.IDENTIFIER )
            return false
          case 11
            if (_scan_pattern_6.scan(_scanner))
              buffer.print(' ')
              if (_scan_pattern_1.scan(_scanner,buffer))
                _scan_table_2.reset
                contingent
                  necessary (_scan_table_2.accept(forEach in buffer))
                  which (_scan_table_2.product)
                    case 1
                      _add( TokenType.KEYWORD_GLOBAL_PROPERTIES )
                      return false
                    case 2
                      _add( TokenType.KEYWORD_GLOBAL_METHODS )
                      return false
                    others
                      necessary (false)
                  endWhich
                unsatisfied
                  _throw_syntax_error("Expected 'GLOBAL PROPERTIES' or 'GLOBAL METHODS'.")
                  return false
                endContingent
              endIf
            endIf
          case 12
            _add( TokenType.KEYWORD_AND )
            return false
          case 13
            _add( TokenType.KEYWORD_AS )
            return false
          case 14
            _add( TokenType.KEYWORD_ASSERT )
            return false
          case 15
            _add( TokenType.KEYWORD_AUGMENT )
            return false
          case 16
            _add( TokenType.KEYWORD_BLOCK )
            return false
          case 17
            _add( TokenType.KEYWORD_CASE )
            return false
          case 18
            _add( TokenType.KEYWORD_CATCH )
            return false
          case 19
            _add( TokenType.KEYWORD_CATEGORIES )
            return false
          case 20
            _add( TokenType.KEYWORD_CLASS )
            return false
          case 21
            _add( TokenType.KEYWORD_CONTINGENT )
            return false
          case 22
            _add( TokenType.KEYWORD_DEFINITIONS )
            return false
          case 23
            _add( TokenType.KEYWORD_DOWN_TO )
            return false
          case 24
            _add( TokenType.KEYWORD_ELSE )
            return false
          case 25
            _add( TokenType.KEYWORD_ELSE_IF )
            return false
          case 26
            _add( TokenType.KEYWORD_END_AUGMENT )
            return false
          case 27
            _add( TokenType.KEYWORD_END_BLOCK )
            return false
          case 28
            _add( TokenType.KEYWORD_END_CLASS )
            return false
          case 29
            _add( TokenType.KEYWORD_END_CONTINGENT )
            return false
          case 30
            _add( TokenType.KEYWORD_END_ENUM )
            return false
          case 31
            _add( TokenType.KEYWORD_END_FOR_EACH )
            return false
          case 32
            _add( TokenType.KEYWORD_END_FUNCTION )
            return false
          case 33
            _add( TokenType.KEYWORD_END_IF )
            return false
          case 34
            _add( TokenType.KEYWORD_END_LOOP )
            return false
          case 35
            _add( TokenType.KEYWORD_END_ROUTINE )
            return false
          case 36
            _add( TokenType.KEYWORD_END_SUBCLASS )
            return false
          case 37
            _add( TokenType.KEYWORD_END_TEMPORARILY )
            return false
          case 38
            _add( TokenType.KEYWORD_END_TRY )
            return false
          case 39
            _add( TokenType.KEYWORD_END_USE )
            return false
          case 40
            _add( TokenType.KEYWORD_END_WHICH )
            return false
          case 41
            _add( TokenType.KEYWORD_END_WHILE )
            return false
          case 42
            _add( TokenType.KEYWORD_ENUM )
            return false
          case 43
            _add( TokenType.KEYWORD_ENSURE )
            return false
          case 44
            _add( TokenType.KEYWORD_ESCAPE_BLOCK )
            return false
          case 45
            _add( TokenType.KEYWORD_ESCAPE_CONTINGENT )
            return false
          case 46
            _add( TokenType.KEYWORD_ESCAPE_FOR_EACH )
            return false
          case 47
            _add( TokenType.KEYWORD_ESCAPE_IF )
            return false
          case 48
            _add( TokenType.KEYWORD_ESCAPE_LOOP )
            return false
          case 49
            _add( TokenType.KEYWORD_ESCAPE_TRY )
            return false
          case 50
            _add( TokenType.KEYWORD_ESCAPE_WHICH )
            return false
          case 51
            _add( TokenType.KEYWORD_ESCAPE_WHILE )
            return false
          case 52
            _add( TokenType.KEYWORD_EXPORT )
            return false
          case 53
            _add( TokenType.KEYWORD_FALSE )
            return false
          case 54
            _add( TokenType.KEYWORD_FOR_EACH )
            return false
          case 55
            _add( TokenType.KEYWORD_FUNCTION )
            return false
          case 56
            _add( TokenType.KEYWORD_FUNCTION_TYPE )
            return false
          case 57
            _add( TokenType.KEYWORD_GLOBAL )
            return false
          case 58
            _add( TokenType.KEYWORD_GLOBAL_PROPERTIES )
            return false
          case 59
            _add( TokenType.KEYWORD_GLOBAL_METHODS )
            return false
          case 60
            _add( TokenType.KEYWORD_IF )
            return false
          case 61
            _add( TokenType.KEYWORD_IMPORT )
            return false
          case 62
            _add( TokenType.KEYWORD_INSTANCE_OF )
            return false
          case 63
            _add( TokenType.KEYWORD_IS )
            return false
          case 64
            _add( TokenType.KEYWORD_IS_TYPE )
            return false
          case 65
            _add( TokenType.KEYWORD_LOCAL )
            return false
          case 66
            _add( TokenType.KEYWORD_LOCALIZE )
            return false
          case 67
            _add( TokenType.KEYWORD_LOOP )
            return false
          case 68
            _add( TokenType.KEYWORD_METHOD )
            return false
          case 69
            _add( TokenType.KEYWORD_METHODS )
            return false
          case 70
            _add( TokenType.KEYWORD_MODULE )
            return false
          case 71
            _add( TokenType.KEYWORD_NATIVE_SECTION )
            return false
          case 72
            _add( TokenType.KEYWORD_NATIVE )
            return false
          case 73
            _add( TokenType.KEYWORD_NATIVE_HEADER )
            return false
          case 74
            _add( TokenType.KEYWORD_NATIVE_CODE )
            return false
          case 75
            _add( TokenType.KEYWORD_NECESSARY )
            return false
          case 76
            _add( TokenType.KEYWORD_NEW )
            return false
          case 77
            _add( TokenType.KEYWORD_NEXT_ITERATION )
            return false
          case 78
            _add( TokenType.KEYWORD_NO_ACTION )
            return false
          case 79
            _add( TokenType.KEYWORD_NOT )
            return false
          case 80
            _add( TokenType.KEYWORD_NULL )
            return false
          case 81
            _add( TokenType.KEYWORD_OR )
            return false
          case 82
            _add( TokenType.KEYWORD_OTHERS )
            return false
          case 83
            _add( TokenType.KEYWORD_PI )
            return false
          case 84
            _add( TokenType.KEYWORD_PRIOR )
            return false
          case 85
            _add( TokenType.KEYWORD_PROPERTIES )
            return false
          case 86
            _add( TokenType.KEYWORD_RETURN )
            return false
          case 87
            _add( TokenType.KEYWORD_ROGO_DIRECTIVE )
            return false
          case 88
            _add( TokenType.KEYWORD_ROUTINE )
            return false
          case 89
            _add( TokenType.KEYWORD_SATISFIED )
            return false
          case 90
            _add( TokenType.KEYWORD_STATES )
            return false
          case 91
            _add( TokenType.KEYWORD_SUBCLASS )
            return false
          case 92
            _add( TokenType.KEYWORD_SUFFICIENT )
            return false
          case 93
            _add( TokenType.KEYWORD_SWAP_VALUES )
            return false
          case 94
            _add( TokenType.KEYWORD_TEMPORARILY )
            return false
          case 95
            _add( TokenType.KEYWORD_THIS )
            return false
          case 96
            _add( TokenType.KEYWORD_THIS_TYPE )
            return false
          case 97
            _add( TokenType.KEYWORD_THROW )
            return false
          case 98
            _add( TokenType.KEYWORD_TRACE )
            return false
          case 99
            _add( TokenType.KEYWORD_TRUE )
            return false
          case 100
            _add( TokenType.KEYWORD_TRY )
            return false
          case 101
            _add( TokenType.KEYWORD_UNDEFINED )
            return false
          case 102
            _add( TokenType.KEYWORD_UNSATISFIED )
            return false
          case 103
            _add( TokenType.KEYWORD_USE )
            return false
          case 104
            _add( TokenType.KEYWORD_USES )
            return false
          case 105
            _add( TokenType.KEYWORD_WHICH )
            return false
          case 106
            _add( TokenType.KEYWORD_WHILE )
            return false
          case 107
            _add( TokenType.KEYWORD_WITH )
            return false
          case 108
            _add( TokenType.KEYWORD_XOR )
            return false
          others
            necessary (false)
        endWhich
      unsatisfied
        _add( TokenType.IDENTIFIER )
        return false
      endContingent
      return true

    method r_scan_number->Logical
      if (((not _scan_pattern_7.is_next(_scanner)) or _scan_pattern_8.is_next(_scanner)))
        return true
      endIf
      _scan_table_3.reset
      contingent
        block n=1
          while (_scanner.has_another(n))
            if (not _scan_table_3.accept(_scanner.peek(n-1)))
              escapeWhile
            endIf
            ++n
          endWhile
          necessary (_scan_table_3.has_product)
          loop (_scan_table_3.match_count) _scanner.read
        endBlock
        which (_scan_table_3.product)
          case 1
            base = 2
            if (not r_scan_binary_integer) return false
            _add( TokenType.BINARY_INTEGER )
            return false
          case 2
            base = 8
            if (not r_scan_octal_integer) return false
            _add( TokenType.OCTAL_INTEGER )
            return false
          case 3
            base = 16
            if (not r_scan_hex_integer) return false
            _add( TokenType.HEX_INTEGER )
            return false
          others
            necessary (false)
        endWhich
      unsatisfied
        if (not r_scan_integer) return false
        if (_scanner.next_is('.'))
          ch = _scanner.peek (1)
          if ((((((ch>='a') and (ch<='z')) or ((ch>='A') and (ch<='Z'))) or (ch=='_')) or (ch=='.')))
            _add( TokenType.INTEGER )
            return false
          endIf
        endIf
        if ((not _scan('.')))
          _add( TokenType.INTEGER )
          return false
        endIf
        if (not r_scan_integer) return false
        if (_scan_pattern_9.scan(_scanner,buffer))
          _scan_pattern_10.scan(_scanner,buffer)
          if ((not _scan_pattern_11.scan(_scanner,buffer)))
            _throw_syntax_error("Integer exponent expected.")
            return false
          endIf
        endIf
        _add( TokenType.REAL_NUMBER )
        return false
      endContingent

    method r_scan_integer->Logical
      while (_scan_pattern_11.scan(_scanner,buffer))
        if ((not _scan_pattern_12.scan(_scanner)))
          return true
        endIf
      endWhile
      return true

    method r_scan_binary_integer->Logical
      while (_scan_pattern_13.scan(_scanner,buffer))
        if ((not _scan_pattern_12.scan(_scanner)))
          return true
        endIf
      endWhile
      return true

    method r_scan_octal_integer->Logical
      while (_scan_pattern_14.scan(_scanner,buffer))
        if ((not _scan_pattern_12.scan(_scanner)))
          return true
        endIf
      endWhile
      return true

    method r_scan_hex_integer->Logical
      while (_scan_pattern_15.scan(_scanner,buffer))
        if ((not _scan_pattern_12.scan(_scanner)))
          return true
        endIf
      endWhile
      return true

    method r_tokenize_string->Logical
      if (not r_scan_string) return false
      _add( TokenType.STRING )
      return false

    method r_scan_string->Logical
      while ((_scanner.has_another and (not _scanner.next_is('"'))))
        if (not r_scan_character) return false
      endWhile
      _must_consume( '"' )
      return true

    method r_tokenize_character_or_string->Logical
      if (_scanner.consume('\''))
        _add( TokenType.STRING )
        return false
      endIf
      if (not r_scan_character) return false
      if (_scanner.consume('\''))
        _add( TokenType.CHARACTER )
        return false
      endIf
      while ((_scanner.has_another and (not _scanner.next_is('\''))))
        if (not r_scan_character) return false
      endWhile
      _must_consume( '\'' )
      _add( TokenType.STRING )
      return false

    method r_scan_single_quote_string->Logical
      while ((_scanner.has_another and (not _scanner.next_is('\''))))
        if (not r_scan_character) return false
      endWhile
      _must_consume( '\'' )
      return true

    method r_tokenize_two_quote_string->Logical
      if (not r_scan_two_quote_string) return false
      _add( TokenType.STRING )
      return false

    method r_scan_two_quote_string->Logical
      while ((_scanner.has_another and (not _next_is("''"))))
        if (not r_scan_character) return false
      endWhile
      _must_consume( "''" )
      return true

    method r_scan_character->Logical
      if ((not _scanner.has_another))
        _throw_syntax_error("Unterminated string - unexpected end of file.")
        return false
      endIf
      ch = _scanner.read
      if ((ch=='\n'))
        _throw_syntax_error("Unterminated string - unexpected end of line.")
        return false
      endIf
      if ((ch!='\\'))
        buffer.print(ch)
        return true
      endIf
      if (_scanner.consume('b'))
        buffer.print(8->Character)
        return true
      endIf
      if (_scanner.consume('e'))
        buffer.print(27->Character)
        return true
      endIf
      if (_scanner.consume('f'))
        buffer.print(12->Character)
        return true
      endIf
      if (_scanner.consume('n'))
        buffer.print('\n')
        return true
      endIf
      if (_scanner.consume('r'))
        buffer.print('\r')
        return true
      endIf
      if (_scanner.consume('t'))
        buffer.print('\t')
        return true
      endIf
      if (_scanner.consume('v'))
        buffer.print(11->Character)
        return true
      endIf
      if (_scanner.consume('0'))
        buffer.print(0->Character)
        return true
      endIf
      if (_scanner.consume('/'))
        buffer.print('/')
        return true
      endIf
      if (_scanner.consume('?'))
        buffer.print('?')
        return true
      endIf
      if (_scanner.consume('\''))
        buffer.print('\'')
        return true
      endIf
      if (_scanner.consume('\\'))
        buffer.print('\\')
        return true
      endIf
      if (_scanner.consume('"'))
        buffer.print('"')
        return true
      endIf
      if (_scanner.consume('x'))
        hex2 = 0
        if (not r_read_hex2) return false
        buffer.print(hex2->Character)
        return true
      endIf
      if (_scanner.consume('u'))
        if (not r_read_hex4) return false
        buffer.print(hex4->Character)
        return true
      endIf
      if (_scanner.consume('['))
        hex_digit = 0
        if (not r_read_hex_digit) return false
        value = hex_digit
        digits = 1
        while (((digits<6) and _scan_pattern_16.is_next(_scanner)))
          if (not r_read_hex_digit) return false
          value = ((value * 16) + hex_digit)
          ++digits
        endWhile
        _must_consume( ']' )
        buffer.print(value->Character)
        return true
      endIf
      buffer.clear.print ""
      buffer.print("Invalid escape sequence '\\").print(ch)
      buffer.print("'. Supported: \\b \\e \\f \\n \\r \\t \\v \\0 \\? \\/ \\' \\\\ \\\" \\xHH \\uHHHH \\[H*].")
      _throw_syntax_error(buffer)
      return false
      return true

    method r_read_hex4->Logical
      if (not r_read_hex2) return false
      hex4 = (hex2 * 256)
      if (not r_read_hex2) return false
      hex4 = (hex4 + hex2)
      return true

    method r_read_hex2->Logical
      if (not r_read_hex_digit) return false
      hex2 = (hex_digit * 16)
      if (not r_read_hex_digit) return false
      hex2 = (hex2 + hex_digit)
      return true

    method r_read_hex_digit->Logical
      if ((not _scan_pattern_16.is_next(_scanner)))
        _throw_syntax_error("Hex digit expected (0-9, a-f, or A-F).")
        return false
      endIf
      ch = _scanner.read
      if (((ch>='a') and (ch<='f')))
        hex_digit = ((ch - 'a'->Int32) + 10)
      elseIf (((ch>='A') and (ch<='F')))
        hex_digit = ((ch - 'A'->Int32) + 10)
      else
        hex_digit = (ch - '0'->Int32)
      endIf
      return true

    method r_tokenize_verbatim_string->Logical
      if (not r_scan_verbatim_string) return false
      _add( TokenType.STRING )
      return false

    method r_scan_verbatim_string->Logical
      while (_scanner.has_another)
        _scan_pattern_3.scan(_scanner,buffer)
        _save_position
        _scanner.consume('\n')
        _scan_pattern_17.scan(_scanner)
        if ((not _scanner.consume('|')))
          _restore_position
          return true
        else
          _discard_position
          buffer.print('\n')
        endIf
      endWhile
      return true

endClass
