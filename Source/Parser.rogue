module R2
uses Utility/WorkList

# Generated by Froley. Will not be overwritten; customize as desired.
$include "ParserCore.rogue"

class Parser : ParserCore
  PROPERTIES
    processed_tokens : Token[]
    marked_token     : Token
    token_buffer     = Token[]
    inserted_tokens  = Token[]

  METHODS
    method preprocess
      processed_tokens = Token[]( _tokens.count * 1.2 )
      parse( ip_preprocess )
      _tokens.clear
      _tokens.add( processed_tokens )

    method create_definition
      local def_name = buffer->String
      Program.definitions[ def_name ] = token_buffer
      use history = WorkList<<String>>
        detect_definition_cycle( history, def_name, token_buffer )
      endUse
      token_buffer = Token[]

    method collect_next_token
      token_buffer.add( _read )

    method collect_token_string
      buffer.print _cur_t->String

    method detect_definition_cycle( history:String[], name:String, tokens:Token[] )
      if (history.contains(name))
        throw marked_token.error( "Definition of '$' results in an infinite cycle."(name) )
      endIf

      history.add( name )
      forEach (t in tokens)
        if (t.type == TokenType.IDENTIFIER)
          local entry = Program.definitions.find( t->String )
          if (entry)
            detect_definition_cycle( history, entry.key, entry.value )
          endIf
        endIf
      endForEach
      history.remove_last

    method insert_definition
      local def = Program.definitions[ _cur_t->String ]
      if (def) insert_definition( forEach in def step -1 )
      else     processed_tokens.add( _cur_t )

    method insert_definition( t:Token )
      if (t.type == TokenType.IDENTIFIER)
        local def = Program.definitions[ t->String ]
        if (def)
          insert_definition( forEach in def step -1 )
          return
        endIf
      endIf
      inserted_tokens.add( t )

    method mark_token
      marked_token = _cur_t

    method has_another->Logical
      return _position < _limit or inserted_tokens.count

    method include_filepath
      Program.include( marked_token, buffer->String )

    method rewrite_token
      processed_tokens.add( _read )

    method _peek->Token
      if (inserted_tokens.count) return inserted_tokens.last
      return prior._peek

    method _read->Token
      if (inserted_tokens.count) return inserted_tokens.remove_last
      return prior._read
endClass
