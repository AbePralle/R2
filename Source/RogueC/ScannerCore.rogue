module R2

# Generated by Froley. WARNING: WILL BE OVERWRITTEN.

$include "CompileError.rogue"
$include "ScanTable.rogue"
$include "Token.rogue"
$include "TokenType.rogue"

class ScannerCore [abstract]
  DEFINITIONS
    ip_tokenize_another = 0
    ip_scan_comment = 1
    ip_scan_id_or_keyword = 2
    ip_scan_number = 3
    ip_scan_integer = 4
    ip_scan_binary_integer = 5
    ip_scan_octal_integer = 6
    ip_scan_hex_integer = 7
    ip_tokenize_string = 8
    ip_scan_string = 9
    ip_tokenize_character_or_string = 10
    ip_scan_single_quote_string = 11
    ip_tokenize_two_quote_string = 12
    ip_scan_two_quote_string = 13
    ip_scan_character = 14
    ip_read_hex4 = 15
    ip_read_hex2 = 16
    ip_read_hex_digit = 17
    ip_tokenize_verbatim_string = 18
    ip_scan_verbatim_string = 19

  PROPERTIES
    _filepath     : String
    _scanner      : ::Scanner
    line          = 1
    column        = 1

    tokens        = Token[]
    buffer        = StringBuilder()
    output        = StringBuilder()

    start_ip      = 0
    ip            : Int32
    halt          = false

    _position_stack = Int32[]
    _line_stack     = Int32[]
    _column_stack   = Int32[]

    # GENERATED PROPERTIES
    count     : Int32
    ch        : Character
    base      : Int32
    hex2      : Int32
    hex4      : Int32
    hex_digit : Int32
    value     : Int32
    digits    : Int32
    _scan_pattern_0 = ScanPattern( "[ \r\t]*" )
    _scan_pattern_1 = ScanPattern( "[_a-zA-Z0-9]*" )
    _scan_pattern_2 = ScanPattern( "[^\n]*" )
    _scan_pattern_3 = ScanPattern( "{----[-]*}" )
    _scan_pattern_4 = ScanPattern( "{====[=]*}" )
    _scan_pattern_5 = ScanPattern( "{[_a-zA-Z][_a-zA-Z0-9]*}" )
    _scan_pattern_6 = ScanPattern( "[ ]+" )
    _scan_pattern_7 = ScanPattern( "[0-9]" )
    _scan_pattern_8 = ScanPattern( "{[.][0-9]}" )
    _scan_pattern_9 = ScanPattern( "[eE]" )
    _scan_pattern_10 = ScanPattern( "[+-]" )
    _scan_pattern_11 = ScanPattern( "[0-9]+" )
    _scan_pattern_12 = ScanPattern( "[_]+" )
    _scan_pattern_13 = ScanPattern( "[01]+" )
    _scan_pattern_14 = ScanPattern( "[0-7]+" )
    _scan_pattern_15 = ScanPattern( "[0-9A-Fa-f]+" )
    _scan_pattern_16 = ScanPattern( "[0-9a-fA-F]" )
    _scan_pattern_17 = ScanPattern( "[ ]*" )
    _scan_table_0 = ScanTable("gjb/Hgo+IkAnQkBIJFImgQgtgQ4qgRxcgSIhgSRegSp9gSxdgS4pgTA6gTIsgWR8gWZbgXA9gXY+gXw8ggZ7ghAoghIlghQughorghw/giY7giwvgi5+gjQAAAEAAgEnRgMACgJ8TltQBAAeAP8CZFhpbv8BZVz/AWZg/wFpZP8Bbmj/AWVsBQD/AW5y/wFjdv8BbHr/AXV+/wFkgQL/AWWBBgYABwE9gQw6ACEDPoEWLYEYPYEaCAAiADYACQE9gSA3AAsADAE9gSgjAA0ADgAPABAAEQM6gTo8gTw+gUoSAP8BPIFA/wE6gUQcAT2BSB0A/wE+gU7/AjqBVD6BWi0BPYFYLgD/ATqBXi8BPYFiMAATADQCfIFsPYFuFAA7ACUBXYF0FQAXAT2BehYAGQI9ggI+ggQYABoAHwI9ggw8gg4bACAAJAAmACcBPYIYOQAoACkCK4IiPYIkKgA1ACsBOoIqLAAxADIBPYIyOAAzAA==")
    _scan_table_1 = ScanTable("h04AFUcsYYEKYoEsY4E+bYFQZYF6ZoM4Z4NiaYN4bIQqTYREToReboR0b4VicIVoUIYGcoYsdIZadYcEd4cyeIdE/wFMMP8BTzT/AUI4/wFBPP8BTEABASBE/wJQSk1w/wFSTv8BT1L/AVBW/wFFWv8BUl7/AVRi/wFJZv8BRWr/AVNuFAD/AUV0/wFUeP8BSHz/AU+BAP8BRIEE/wFTgQgVAP8CboEQdYEW/wFkgRQCAP8BZ4Ea/wFtgR7/AWWBIv8BboEm/wF0gSoDAP8BbIEw/wFvgTT/AWOBOP8Ba4E8BAD/AWyBQv8BYYFG/wFzgUr/AXOBTgUA/wJvgVZlgWj/AWSBWv8BdYFe/wFsgWL/AWWBZgYA/wF0gWz/AWiBcP8Bb4F0/wFkgXgbAP8DbIICboIUeIMm/wFzggb/AWWCCgcBSYIO/wFmghIIAP8BZIIY/wdCgihDgjpGgkxJgmZMgmxSgnpXgxT/AWyCLP8Bb4Iw/wFjgjT/AWuCOAkA/wFsgj7/AWGCQv8Bc4JG/wFzgkoKAP8Bb4JQ/wFyglT/AUWCWP8BYYJc/wFjgmD/AWiCZAsA/wFmgmoMAP8Bb4Jw/wFvgnT/AXCCeA0A/wFvgn7/AXWDAv8BdIMG/wFpgwr/AW6DDv8BZYMSDgD/AWiDGP8BaYMc/wFsgyD/AWWDJA8A/wFwgyr/AW+DLv8BcoMy/wF0gzYQAP8CYYM+b4NM/wFsg0L/AXODRv8BZYNKEQD/AXKDUP8BRYNU/wFhg1j/AWODXP8BaINgEgD/AWyDZv8Bb4Nq/wFig27/AWGDcv8BbIN2EwD/A2aEAG2EAm6EFBYA/wFwhAb/AW+ECv8BcoQO/wF0hBIXAP8BY4QY/wFshBz/AXWEIP8BZIQk/wFlhCgYAP8Bb4Qu/wJjhDRvhD7/AWGEOP8BbIQ8GQD/AXCEQhoA/wFFhEj/AVSETP8BSIRQ/wFPhFT/AUSEWP8BU4RcHAD/AUGEYv8BVIRm/wFJhGr/AVaEbv8BRYRyHQD/A2GEfG+FOnWFWP8BdIUA/wFphQT/AXaFCP8BZYUM/wFDhRAeAkiFFkOFLP8BZYUa/wFhhR7/AWSFIv8BZYUm/wFyhSofAP8Bb4Uw/wFkhTT/AWWFOCAA/wJBhUB0hVb/AWOFRP8BdIVI/wFphUz/AW+FUP8BboVUIQAiAP8BbIVc/wFshWAjAP8BcoVmJAD/AmmFbnKFcCUA/wFphXT/AW6FeP8BdIV8JgFshgD/AW6GBCcA/wFShgr/AU+GDv8BUIYS/wFFhhb/AVKGGv8BVIYe/wFJhiL/AUWGJv8BU4YqKAD/AmWGMm+GRP8BdIY2/wF1hjr/AXKGPv8BboZCKQD/AXWGSP8BdIZM/wFphlD/AW6GVP8BZYZYKgD/AmiGYHKGev8BaYZk/wFzhmj/AUOGbP8BYYZw/wFshnT/AWyGeCsA/wF1hn7/AWWHAiwA/wJuhwpzhyj/AWSHDv8BZYcS/wFmhxb/AWmHGv8Bboce/wFlhyL/AWSHJi0A/wFlhyz/AXOHMC4A/wFohzb/AWmHOv8BbIc+/wFlh0IvAP8Bb4dI/wFyh0wwAA==")
    _scan_table_2 = ScanTable("YgABRwT/AUwI/wFPDP8BQhD/AUEU/wFMGP8BIBz/AlAiTUj/AVIm/wFPKv8BUC7/AUUy/wFSNv8BVDr/AUk+/wFFQv8BU0YBAP8BRUz/AVRQ/wFIVP8BT1j/AURc/wFTYAIA")
    _scan_table_3 = ScanTable("EgABMAT/A2IMYw54EAEAAgADAA==")

  METHODS
    method init( file:File )
      init( file.filepath, ::Scanner(file) )
      line   = 1
      column = 1

    method init( filepath:String, content:String, line=1, column=1 )
      init( filepath, ::Scanner(content).[line=line, column=column] )

    method init( _filepath, _scanner )
      noAction

    method execute( ip:Int32 )
      _clear_state
      _execute( ip )

    method tokenize( ip=null:Int32? )->Token[]
      if (ip) start_ip = ip.value
      _clear_state
      while (_execute(start_ip) or not halt)
        buffer.clear
      endWhile
      _on_output_line # flush any buffered output
      return tokens

    method _add( type:TokenType )
      if (type.attributes & TokenType.ATTRIBUTE_CONTENT)
        tokens.add( _t(type,buffer) )
      else
        tokens.add( _t(type) )
      endIf
      buffer.clear

    method _clear_state
      tokens = Token[]
      buffer.clear
      output.clear
      halt = false

    method _describe_character( c:Character )->String
      if (c == 10 or c == 13)       return "end of line";
      elseIf (c >= 32 and c != 127) return "'$'" (c)
      else                          return "'$'" (c.to_escaped_ascii)

    method _is_next( text:String )->Logical
      local location = _scanner.location
      local result = _scanner.consume( text )
      _scanner.location = location
      return result

    method _must_consume( ch:Character )
      if (_scanner.consume(ch)) return
      local message = "Syntax error - expected $, found " (_describe_character(ch))
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _must_consume( st:String )
      if (_scanner.consume(st)) return
      _throw_expected_string_error( "'$'" (st.to_escaped_ascii("'")) )

    method _must_consume( pattern:ScanPattern )
      if (pattern.scan(_scanner)) return
      _throw_expected_string_error( pattern->String )

    method _next_is( text:String )->Logical
      if (not _scanner.has_another(text.count)) return false
      local pos = _scanner.position
      forEach (ch at index in text)
        if (ch != _scanner.data[pos+index]) return false
      endForEach
      return true

    method _on_output_line
      # Default behavior: print out 'output' and clear it. Can override this method.
      print( output ).flush
      output.clear

    method _restore_position
      if (_position_stack.is_empty)
        _throw_syntax_error( "restorePosition without prior savePosition." )
      endIf
      _scanner.position = _position_stack.remove_last
      _scanner.line     = _line_stack.remove_last
      _scanner.column   = _column_stack.remove_last

    method _save_position
      _position_stack.add( _scanner.position )
      _line_stack.add( _scanner.line )
      _column_stack.add( _scanner.column )

    method _scan( ch:Character )->Logical
      if (not _scanner.consume(ch)) return false
      buffer.print ch
      return true

    method _scan( text:String )->Logical
      if (not _scanner.consume(text)) return false
      buffer.print text
      return true

    method _t( type:TokenType, content=null:String )->Token
      return Token( type, _filepath, _scanner.source, line, column, content )

    method _throw_expected_string_error( st:String )
      local message = "Syntax error - expected $, found " (st)
      if (_scanner.has_another) message += _describe_character(_scanner.peek) + "."
      else                      message += "end of input."
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _throw_syntax_error( message=null:String )
      if (not message)
        local builder = StringBuilder()
        builder.print "Syntax error - unexpected "
        if (not _scanner.has_another)
          builder.println "end of input."
        else
          builder.print( _describe_character(_scanner.peek) ).print( '.' )
        endIf
        message = builder->String
      endIf
      throw CompileError( message, _filepath, _scanner.source, _scanner.line, _scanner.column )

    method _execute( ip:Int32 )->Logical
      loop
        ++ip
        which (ip-1)
          case ip_tokenize_another
            _scan_pattern_0.scan(_scanner)
            line   = _scanner.line
            column = _scanner.column
            if (not _execute(ip_scan_comment)) return false
            if ((not _scanner.has_another))
              _add( TokenType.EOL )
              halt = true
              return false
            endIf
            _scan_table_0.reset
            contingent
              block n=1
                while (_scanner.has_another(n))
                  if (not _scan_table_0.accept(_scanner.peek(n-1)))
                    escapeWhile
                  endIf
                  ++n
                endWhile
                necessary (_scan_table_0.has_product)
                loop (_scan_table_0.match_count) _scanner.read
              endBlock
              which (_scan_table_0.product)
                case 0
                  _add( TokenType.EOL )
                  return false
                case 1
                  if (not _execute(ip_tokenize_string)) return false
                case 2
                  if (not _execute(ip_tokenize_character_or_string)) return false
                case 3
                  if (not _execute(ip_tokenize_two_quote_string)) return false
                case 4
                  if (not _execute(ip_tokenize_verbatim_string)) return false
                case 5
                  _add( TokenType.META_DEFINE )
                  return false
                case 6
                  _add( TokenType.META_INCLUDE )
                  return false
                case 7
                  _add( TokenType.SYMBOL_AMPERSAND )
                  return false
                case 8
                  _add( TokenType.SYMBOL_ARROW )
                  return false
                case 9
                  _add( TokenType.SYMBOL_ASTERISK )
                  return false
                case 10
                  _add( TokenType.SYMBOL_AT )
                  return false
                case 11
                  _add( TokenType.SYMBOL_BACKSLASH )
                  return false
                case 12
                  _add( TokenType.SYMBOL_BANG )
                  return false
                case 13
                  _add( TokenType.SYMBOL_CARET )
                  return false
                case 14
                  _add( TokenType.SYMBOL_CLOSE_CURLY )
                  return false
                case 15
                  _add( TokenType.SYMBOL_CLOSE_SQUARE )
                  return false
                case 16
                  _add( TokenType.SYMBOL_CLOSE_PAREN )
                  return false
                case 17
                  _add( TokenType.SYMBOL_COLON )
                  return false
                case 18
                  _add( TokenType.SYMBOL_COLON_COLON )
                  return false
                case 19
                  _add( TokenType.SYMBOL_COMMA )
                  return false
                case 20
                  _add( TokenType.SYMBOL_DOUBLE_VERTICAL_BAR )
                  return false
                case 21
                  _add( TokenType.SYMBOL_EMPTY_SQUARE_BRACKETS )
                  return false
                case 22
                  _add( TokenType.SYMBOL_EQ )
                  return false
                case 23
                  _add( TokenType.SYMBOL_EQUALS )
                  return false
                case 24
                  _add( TokenType.SYMBOL_GE )
                  return false
                case 25
                  _add( TokenType.SYMBOL_GT )
                  return false
                case 26
                  _add( TokenType.SYMBOL_GTGT )
                  return false
                case 27
                  _add( TokenType.SYMBOL_LE )
                  return false
                case 28
                  _add( TokenType.SYMBOL_LEFT_SHIFT )
                  return false
                case 29
                  _add( TokenType.SYMBOL_LEFT_SHIFT_EQUALS )
                  return false
                case 30
                  _add( TokenType.SYMBOL_LITERAL_OPEN_SQUARE )
                  return false
                case 31
                  _add( TokenType.SYMBOL_LT )
                  return false
                case 32
                  _add( TokenType.SYMBOL_LTLT )
                  return false
                case 33
                  _add( TokenType.SYMBOL_MINUS )
                  return false
                case 34
                  _add( TokenType.SYMBOL_MINUS_MINUS )
                  return false
                case 35
                  _add( TokenType.SYMBOL_NE )
                  return false
                case 36
                  _add( TokenType.SYMBOL_OPEN_CURLY )
                  return false
                case 37
                  _add( TokenType.SYMBOL_OPEN_SQUARE )
                  return false
                case 38
                  _add( TokenType.SYMBOL_OPEN_PAREN )
                  return false
                case 39
                  _add( TokenType.SYMBOL_PERCENT )
                  return false
                case 40
                  _add( TokenType.SYMBOL_PERIOD )
                  return false
                case 41
                  _add( TokenType.SYMBOL_PLUS )
                  return false
                case 42
                  _add( TokenType.SYMBOL_PLUS_PLUS )
                  return false
                case 43
                  _add( TokenType.SYMBOL_QUESTION )
                  return false
                case 44
                  _add( TokenType.SYMBOL_QUESTION_COLON )
                  return false
                case 45
                  _add( TokenType.SYMBOL_RIGHT_SHIFT )
                  return false
                case 46
                  _add( TokenType.SYMBOL_RIGHT_SHIFT_EQUALS )
                  return false
                case 47
                  _add( TokenType.SYMBOL_RIGHT_SHIFT_X )
                  return false
                case 48
                  _add( TokenType.SYMBOL_RIGHT_SHIFT_X_EQUALS )
                  return false
                case 49
                  _add( TokenType.SYMBOL_SEMICOLON )
                  return false
                case 50
                  _add( TokenType.SYMBOL_SLASH )
                  return false
                case 51
                  _add( TokenType.SYMBOL_TILDE )
                  return false
                case 52
                  _add( TokenType.SYMBOL_VERTICAL_BAR )
                  return false
                case 53
                  _add( TokenType.SYMBOL_PLUS_EQUALS )
                  return false
                case 54
                  _add( TokenType.SYMBOL_MINUS_EQUALS )
                  return false
                case 55
                  _add( TokenType.SYMBOL_TIMES_EQUALS )
                  return false
                case 56
                  _add( TokenType.SYMBOL_DIVIDE_EQUALS )
                  return false
                case 57
                  _add( TokenType.SYMBOL_MOD_EQUALS )
                  return false
                case 58
                  _add( TokenType.SYMBOL_AND_EQUALS )
                  return false
                case 59
                  _add( TokenType.SYMBOL_OR_EQUALS )
                  return false
                others
                  necessary (false)
              endWhich
            endContingent
            if (_scan('$'))
              if (_scan_pattern_1.scan(_scanner,buffer))
                _add( TokenType.PLACEHOLDER )
                return false
              endIf
              _add( TokenType.SYMBOL_DOLLAR )
              return false
            endIf
            if (not _execute(ip_scan_id_or_keyword)) return false
            if (not _execute(ip_scan_number)) return false
            _throw_syntax_error
            return true
          case ip_scan_comment
            if (_scanner.consume('#'))
              if (_scanner.consume('{'))
                count = 1
                while (_scanner.has_another)
                  ch = _scanner.read
                  if ((ch=='\n'))
                    _add( TokenType.EOL )
                  elseIf ((ch=='#'))
                    if (_scanner.consume('{'))
                      ++count
                    endIf
                  elseIf ((ch=='}'))
                    if (_scanner.consume('#'))
                      --count
                      if ((count==0))
                        return false
                      endIf
                    endIf
                  endIf
                endWhile
                _throw_syntax_error("Unterminated multi-line comment.")
              else
                if (_scan_pattern_2.scan(_scanner,buffer))
                  _scanner.consume('\n')
                  _add( TokenType.EOL )
                  return false
                endIf
              endIf
            elseIf ((_scan_pattern_3.scan(_scanner) or _scan_pattern_4.scan(_scanner)))
              _scan_pattern_2.scan(_scanner,buffer)
              _scanner.consume('\n')
              _add( TokenType.EOL )
              return false
            else
              return true
            endIf
            return true
          case ip_scan_id_or_keyword
            if ((not _scan_pattern_5.scan(_scanner,buffer)))
              return true
            endIf
            _scan_table_1.reset
            contingent
              necessary (_scan_table_1.accept(forEach in buffer))
              which (_scan_table_1.product)
                case 1
                  if (_scan_pattern_6.scan(_scanner))
                    buffer.print(' ')
                    if (_scan_pattern_5.scan(_scanner,buffer))
                      _scan_table_2.reset
                      contingent
                        necessary (_scan_table_2.accept(forEach in buffer))
                        which (_scan_table_2.product)
                          case 1
                            _add( TokenType.KEYWORD_GLOBAL_PROPERTIES )
                            return false
                          case 2
                            _add( TokenType.KEYWORD_GLOBAL_METHODS )
                            return false
                          others
                            necessary (false)
                        endWhich
                      unsatisfied
                        _throw_syntax_error("Expected 'GLOBAL PROPERTIES' or 'GLOBAL METHODS'.")
                      endContingent
                    endIf
                  endIf
                case 2
                  _add( TokenType.KEYWORD_AND )
                  return false
                case 3
                  _add( TokenType.KEYWORD_AUGMENT )
                  return false
                case 4
                  _add( TokenType.KEYWORD_BLOCK )
                  return false
                case 5
                  _add( TokenType.KEYWORD_CLASS )
                  return false
                case 6
                  _add( TokenType.KEYWORD_MODULE )
                  return false
                case 7
                  _add( TokenType.KEYWORD_ELSE )
                  return false
                case 8
                  _add( TokenType.KEYWORD_ELSE_IF )
                  return false
                case 9
                  _add( TokenType.KEYWORD_END_BLOCK )
                  return false
                case 10
                  _add( TokenType.KEYWORD_END_CLASS )
                  return false
                case 11
                  _add( TokenType.KEYWORD_END_FOR_EACH )
                  return false
                case 12
                  _add( TokenType.KEYWORD_END_IF )
                  return false
                case 13
                  _add( TokenType.KEYWORD_END_LOOP )
                  return false
                case 14
                  _add( TokenType.KEYWORD_END_ROUTINE )
                  return false
                case 15
                  _add( TokenType.KEYWORD_END_WHILE )
                  return false
                case 16
                  _add( TokenType.KEYWORD_EXPORT )
                  return false
                case 17
                  _add( TokenType.KEYWORD_FALSE )
                  return false
                case 18
                  _add( TokenType.KEYWORD_FOR_EACH )
                  return false
                case 19
                  _add( TokenType.KEYWORD_GLOBAL )
                  return false
                case 20
                  _add( TokenType.KEYWORD_GLOBAL_PROPERTIES )
                  return false
                case 21
                  _add( TokenType.KEYWORD_GLOBAL_METHODS )
                  return false
                case 22
                  _add( TokenType.KEYWORD_IF )
                  return false
                case 23
                  _add( TokenType.KEYWORD_IMPORT )
                  return false
                case 24
                  _add( TokenType.KEYWORD_INCLUDE )
                  return false
                case 25
                  _add( TokenType.KEYWORD_LOCAL )
                  return false
                case 26
                  _add( TokenType.KEYWORD_LOOP )
                  return false
                case 27
                  _add( TokenType.KEYWORD_METHOD )
                  return false
                case 28
                  _add( TokenType.KEYWORD_METHODS )
                  return false
                case 29
                  _add( TokenType.KEYWORD_NATIVE )
                  return false
                case 30
                  _add( TokenType.KEYWORD_NATIVE_C )
                  return false
                case 31
                  _add( TokenType.KEYWORD_NATIVE_C_HEADER )
                  return false
                case 32
                  _add( TokenType.KEYWORD_NATIVE_C_CODE )
                  return false
                case 33
                  _add( TokenType.KEYWORD_NO_ACTION )
                  return false
                case 34
                  _add( TokenType.KEYWORD_NOT )
                  return false
                case 35
                  _add( TokenType.KEYWORD_NULL )
                  return false
                case 36
                  _add( TokenType.KEYWORD_OR )
                  return false
                case 37
                  _add( TokenType.KEYWORD_PI )
                  return false
                case 38
                  _add( TokenType.KEYWORD_PRINT )
                  return false
                case 39
                  _add( TokenType.KEYWORD_PRINTLN )
                  return false
                case 40
                  _add( TokenType.KEYWORD_PROPERTIES )
                  return false
                case 41
                  _add( TokenType.KEYWORD_RETURN )
                  return false
                case 42
                  _add( TokenType.KEYWORD_ROUTINE )
                  return false
                case 43
                  _add( TokenType.KEYWORD_THIS_CALL )
                  return false
                case 44
                  _add( TokenType.KEYWORD_TRUE )
                  return false
                case 45
                  _add( TokenType.KEYWORD_UNDEFINED )
                  return false
                case 46
                  _add( TokenType.KEYWORD_USES )
                  return false
                case 47
                  _add( TokenType.KEYWORD_WHILE )
                  return false
                case 48
                  _add( TokenType.KEYWORD_XOR )
                  return false
                others
                  necessary (false)
              endWhich
            unsatisfied
              _add( TokenType.IDENTIFIER )
              return false
            endContingent
            return true
          case ip_scan_number
            if (((not _scan_pattern_7.is_next(_scanner)) or _scan_pattern_8.is_next(_scanner)))
              return true
            endIf
            _scan_table_3.reset
            contingent
              block n=1
                while (_scanner.has_another(n))
                  if (not _scan_table_3.accept(_scanner.peek(n-1)))
                    escapeWhile
                  endIf
                  ++n
                endWhile
                necessary (_scan_table_3.has_product)
                loop (_scan_table_3.match_count) _scanner.read
              endBlock
              which (_scan_table_3.product)
                case 1
                  base = 2
                  if (not _execute(ip_scan_binary_integer)) return false
                  _add( TokenType.BINARY_INTEGER )
                  return false
                case 2
                  base = 8
                  if (not _execute(ip_scan_octal_integer)) return false
                  _add( TokenType.OCTAL_INTEGER )
                  return false
                case 3
                  base = 16
                  if (not _execute(ip_scan_hex_integer)) return false
                  _add( TokenType.HEX_INTEGER )
                  return false
                others
                  necessary (false)
              endWhich
            unsatisfied
              if (not _execute(ip_scan_integer)) return false
              if ((not _scan('.')))
                _add( TokenType.INTEGER )
                return false
              endIf
              if (not _execute(ip_scan_integer)) return false
              if (_scan_pattern_9.scan(_scanner,buffer))
                _scan_pattern_10.scan(_scanner,buffer)
                if ((not _scan_pattern_11.scan(_scanner,buffer)))
                  _throw_syntax_error("Integer exponent expected.")
                endIf
              endIf
              _add( TokenType.REAL_NUMBER )
              return false
            endContingent
            return true
          case ip_scan_integer
            while (_scan_pattern_11.scan(_scanner,buffer))
              if ((not _scan_pattern_12.scan(_scanner)))
                return true
              endIf
            endWhile
            return true
          case ip_scan_binary_integer
            while (_scan_pattern_13.scan(_scanner,buffer))
              if ((not _scan_pattern_12.scan(_scanner)))
                return true
              endIf
            endWhile
            return true
          case ip_scan_octal_integer
            while (_scan_pattern_14.scan(_scanner,buffer))
              if ((not _scan_pattern_12.scan(_scanner)))
                return true
              endIf
            endWhile
            return true
          case ip_scan_hex_integer
            while (_scan_pattern_15.scan(_scanner,buffer))
              if ((not _scan_pattern_12.scan(_scanner)))
                return true
              endIf
            endWhile
            return true
          case ip_tokenize_string
            if (not _execute(ip_scan_string)) return false
            _add( TokenType.STRING )
            return false
          case ip_scan_string
            while ((_scanner.has_another and (not _scanner.next_is('"'))))
              if (not _execute(ip_scan_character)) return false
            endWhile
            _must_consume( '"' )
            return true
          case ip_tokenize_character_or_string
            if (_scanner.consume('\''))
              _add( TokenType.STRING )
              return false
            endIf
            if (not _execute(ip_scan_character)) return false
            if (_scanner.consume('\''))
              _add( TokenType.CHARACTER )
              return false
            endIf
            while ((_scanner.has_another and (not _scanner.next_is('\''))))
              if (not _execute(ip_scan_character)) return false
            endWhile
            _must_consume( '\'' )
            _add( TokenType.STRING )
            return false
          case ip_scan_single_quote_string
            while ((_scanner.has_another and (not _scanner.next_is('\''))))
              if (not _execute(ip_scan_character)) return false
            endWhile
            _must_consume( '\'' )
            return true
          case ip_tokenize_two_quote_string
            if (not _execute(ip_scan_two_quote_string)) return false
            _add( TokenType.STRING )
            return false
          case ip_scan_two_quote_string
            while ((_scanner.has_another and (not _next_is("''"))))
              if (not _execute(ip_scan_character)) return false
            endWhile
            _must_consume( "''" )
            return true
          case ip_scan_character
            if ((not _scanner.has_another))
              _throw_syntax_error("Unterminated string - unexpected end of file.")
            endIf
            ch = _scanner.read
            if ((ch=='\n'))
              _throw_syntax_error("Unterminated string - unexpected end of line.")
            endIf
            if ((ch!='\\'))
              buffer.print(ch)
              return true
            endIf
            if (_scanner.consume('b'))
              buffer.print(8->Character)
              return true
            endIf
            if (_scanner.consume('e'))
              buffer.print(27->Character)
              return true
            endIf
            if (_scanner.consume('f'))
              buffer.print(12->Character)
              return true
            endIf
            if (_scanner.consume('n'))
              buffer.print('\n')
              return true
            endIf
            if (_scanner.consume('r'))
              buffer.print('\r')
              return true
            endIf
            if (_scanner.consume('t'))
              buffer.print('\t')
              return true
            endIf
            if (_scanner.consume('v'))
              buffer.print(11->Character)
              return true
            endIf
            if (_scanner.consume('0'))
              buffer.print(0->Character)
              return true
            endIf
            if (_scanner.consume('/'))
              buffer.print('/')
              return true
            endIf
            if (_scanner.consume('?'))
              buffer.print('?')
              return true
            endIf
            if (_scanner.consume('\''))
              buffer.print('\'')
              return true
            endIf
            if (_scanner.consume('\\'))
              buffer.print('\\')
              return true
            endIf
            if (_scanner.consume('"'))
              buffer.print('"')
              return true
            endIf
            if (_scanner.consume('x'))
              hex2 = 0
              if (not _execute(ip_read_hex2)) return false
              buffer.print(hex2->Character)
              return true
            endIf
            if (_scanner.consume('u'))
              if (not _execute(ip_read_hex4)) return false
              buffer.print(hex4->Character)
              return true
            endIf
            if (_scanner.consume('['))
              hex_digit = 0
              if (not _execute(ip_read_hex_digit)) return false
              value = hex_digit
              digits = 1
              while (((digits<6) and _scan_pattern_16.is_next(_scanner)))
                if (not _execute(ip_read_hex_digit)) return false
                value = ((value * 16) + hex_digit)
                ++digits
              endWhile
              _must_consume( ']' )
              buffer.print(value->Character)
              return true
            endIf
            buffer.clear.print ""
            buffer.print("Invalid escape sequence '\\").print(ch)
            buffer.print("'. Supported: \\b \\e \\f \\n \\r \\t \\v \\0 \\? \\/ \\' \\\\ \\\" \\xHH \\uHHHH \\[H*].")
            _throw_syntax_error(buffer)
            return true
          case ip_read_hex4
            if (not _execute(ip_read_hex2)) return false
            hex4 = (hex2 * 256)
            if (not _execute(ip_read_hex2)) return false
            hex4 = (hex4 + hex2)
            return true
          case ip_read_hex2
            if (not _execute(ip_read_hex_digit)) return false
            hex2 = (hex_digit * 16)
            if (not _execute(ip_read_hex_digit)) return false
            hex2 = (hex2 + hex_digit)
            return true
          case ip_read_hex_digit
            if ((not _scan_pattern_16.is_next(_scanner)))
              _throw_syntax_error("Hex digit expected (0-9, a-f, or A-F).")
            endIf
            ch = _scanner.read
            if (((ch>='a') and (ch<='f')))
              hex_digit = ((ch - 'a'->Int32) + 10)
            elseIf (((ch>='A') and (ch<='F')))
              hex_digit = ((ch - 'A'->Int32) + 10)
            else
              hex_digit = (ch - '0'->Int32)
            endIf
            return true
          case ip_tokenize_verbatim_string
            if (not _execute(ip_scan_verbatim_string)) return false
            _add( TokenType.STRING )
            return false
          case ip_scan_verbatim_string
            while (_scanner.has_another)
              _scan_pattern_2.scan(_scanner,buffer)
              _scanner.consume('\n')
              _scan_pattern_17.scan(_scanner)
              if ((not _scanner.consume('|')))
                return true
              endIf
              buffer.print('\n')
            endWhile
            return true
          others
            halt = true
            return false
        endWhich
      endLoop

endClass
